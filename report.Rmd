---
title: "Re-analysis of PNG cohort using the Pf3k pipeline"
author: "Stuart Lee"
date: "`r Sys.Date()`"
output: BiocStyle::html_document
---
```{r setup}
# packages
pkgs <- c("moimix", "SeqArray", "dplyr", 
          "readr", "ggplot2", "knitr", "tidyr", "grid")
inst <- lapply(pkgs, library, character.only = TRUE)
# ggplot options
theme_set(theme_bw())
# knitr options
opts_chunk$set(warning = FALSE, echo = FALSE, message = FALSE,
             fig.path = "./report_figures/",
             cache.path = "./report_cache/")
qc_path <- "data/qc/"

# added by bpipe after running post-alignment steps of pipeline
bpipe_prefix <- ".reverted.markilluminaadapters.remapBWA.realignindels.dedup.bqsrApply."
final_vcf <- "cache/final_snps.cleanGDS.gds"

# check OS system
os <- Sys.info()['sysname']

if (os == 'Darwin') {
  # binaries for manipulating VCF files
  vcftools_bin <- "/Users/lee.s/anaconda/bin/vcftools"
  vcf2npy_bin <- "/Users/lee.s/anaconda/envs/py2/bin/vcf2npy"
  vcfnpy2hdf5_bin <-"/Users/lee.s/anaconda/envs/py2/bin/vcfnpy2hdf5"
  bgzip <- "/Users/lee.s/anaconda/envs/py2/bin/bgzip"
  tabix <- "/Users/lee.s/anaconda/envs/py2/bin/tabix -p vcf"
  
  
} else {
  # binaries for manipulating VCF files
  vcftools_bin <- "/usr/local/bioinf/bin/vcftools"
  vcf2npy_bin <- "~/.local/bin/vcf2npy"
  vcfnpy2hdf5_bin <-"~/.local/bin/vcfnpy2hdf5"
  bgzip <- "/usr/local/bioinf/bin/bgzip"
  tabix <- "/usr/local/bioinf/bin/tabix -p vcf"
}

```

# Introduction
Here we describe realignment and variant calling of
152 _P.falciparum_ isolates from Papua New Guinea. 

The new pipeline we created is our attempt at replicating
the Malaria Genomics Pf3k projects analysis pipeline. It
is our hope that we can integrate this updated data into
a global analysis of selection and relatedness. 

For the pipeline documentation and details please see:
https://github.com/bahlolab/pf_variant_calling_pipeline


# Variant and Sample Quality Assessment
Although the pipeline we have written should in principle
output a clean VCF/GDS file as its final output - we just make
sure that the preliminary steps of the pipeline have produced
reasonable output. We also filter samples and/or variants
that are poor quality based on one or more of the following 
characteristics:

* high missingess 
* poor alignment/mapping to the 3D7 reference genome
* poor coverage
* errors caused by sequencing artefacts (i.e. strand bias)

## Alignment summary statistics
We ran Picardtools CollectAlignmentSummary metrics and CollectInsertSizeMetrics 
to find estimates of total read counts, total
reads aligned to the reference, average fragment lengths. These were all
estimated post alignment with BWA-MEM and recalibrating base qualities scores
with GATK.

We summarise the alignment outputs for all samples in the table below,
sorted by proportion of reads passing filtering that align to the reference
genome. 

```{r alignment}
## collect alignment summary
align_metrics <- list.files(qc_path, 
                            pattern = ".alignment_metrics",
                            full.names = TRUE)
read_align <- function(metrics_file) {
    
    x <- read_lines(metrics_file)
    # remove empty lines and header lines
    x <- paste0(x[nzchar(x) & !grepl("^#",x)], collapse = "\n")
    out_metrics <- read_tsv(x)
    out_metrics$sample_id <- sub("(.*\\/)", "\\2", metrics_file)
    out_metrics$sample_id <- sub("\\..*", "\\2", out_metrics$sample_id)
    return(out_metrics)
}

align_df <- bind_rows(lapply(align_metrics, read_align))
align_df_pe <- align_df %>% filter(CATEGORY == "PAIR") %>% 
    select(sample_id, everything(), -CATEGORY, -SAMPLE, -LIBRARY, -READ_GROUP)
# sort by pct_pf_reads_aligned
align_df_clean <-  align_df_pe %>% select(sample_id, 
                                          read_length = MEAN_READ_LENGTH, 
                                          total_reads = TOTAL_READS, 
                                          total_reads_aligned = PF_READS_ALIGNED,
                                          percent_reads_aligned = PCT_PF_READS_ALIGNED,
                                          total_high_qual_reads_aligned = PF_HQ_ALIGNED_READS,
                                          total_q20_bases_aligned = PF_HQ_ALIGNED_Q20_BASES,
                                          total_reads_aligned_in_pairs = READS_ALIGNED_IN_PAIRS,
                                          percent_reads_aligned_in_pairs =PCT_READS_ALIGNED_IN_PAIRS, 
                                          bad_cycles = BAD_CYCLES, 
                                          percent_chimeras = PCT_CHIMERAS, 
                                          percent_adapter = PCT_ADAPTER) %>%
    mutate(percent_high_qual_aligned = total_high_qual_reads_aligned / total_reads) %>% 
    arrange(desc(percent_reads_aligned), desc(read_length))

kable(align_df_clean, digits = 1, format = "markdown")

```

We see that several isolates have not aligned at all to the 3D7 reference genome,
or are poorly aligned to reference genome. These isolates have been found 
in our other pipeline to align completely to the Pvivax genome or have very
low quantities of parasite DNA or have high amounts of adapter contamination. 

We also look at the insert size distributions and save the output for checking
clonality in estMOI. Everything looks fine here - not much difference between
means and median insert size distributions.

```{r insert-size metrics}
# insert files
insert_metrics <- list.files(qc_path, 
                            pattern = ".insert_metrics",
                            full.names = TRUE)


read_insert <- function(metrics_file) {
    x <- read_lines(metrics_file)
    summary_distribution <- paste(x[c(7,8)], collapse="\n")
    insert_df <- read_tsv(summary_distribution)
    insert_df$sample_id <- sub("(.*\\/)", "\\2", metrics_file)
    insert_df$sample_id <- sub("\\..*", "\\2", insert_df$sample_id)
    return(insert_df)
}

insert_all <- lapply(insert_metrics, read_insert) %>% bind_rows()


# save as rds file join to alignment stats
ggplot(insert_all, aes(x = MEDIAN_INSERT_SIZE, y = MEAN_INSERT_SIZE)) +
    geom_point() + xlab("median insert size") + ylab("mean insert size")


```


## Depth of coverage 
We estimated coverage using GATK's Depth of Coverage both within
sample and over genomic intervals that overlap known drug resistance
genes and surface antigen genes. For both coverage estimates we restricted
counting to only include bases where the base-quality score was greater
than 20 and only include reads where the mapping-quality score
was greater than 20.

First we plot the distributions of mean coverage, median coverage, 
and the proportion of bases covered up to 1, 5, and 10 reads respectively. 

```{r dp-read, fig.align='centre', fig.cap="Boxplots of coverage statistics"}
dp_pattern <- ".reverted.markilluminaadapters.remapBWA.realignindels.dedup.bqsrApply.sample_summary"

# 
dp_summary <- list.files(qc_path, 
                         pattern = dp_pattern, 
                         full.names = TRUE)

dp_df <- lapply(dp_summary, read_tsv, n_max = 1) %>% 
    bind_rows() %>% 
    mutate(centre = ifelse(grepl("^PNG", sample_id), "Broad", "WTSI"))


stopifnot(nrow(dp_df) == length(dp_summary))

# gather stats 
dp_tidy <- dp_df %>% 
    select(sample_id, mean, median = granular_median, starts_with('%')) %>% 
    gather(statistic, value, mean, median, starts_with('%'), -sample_id) %>% 
    mutate(category = ifelse(grepl("^me", statistic), "central", "percentage"))

ggplot(dp_tidy %>% filter(category == "percentage"), 
       aes(x = value, color = statistic)) +
    stat_ecdf() +
    ylab("proportion of samples") + xlab("percentage")

ggplot(dp_tidy %>% filter(category == "central"), 
       aes(x = factor(statistic), y = value)) +
    geom_boxplot() + ylab("depth") + xlab("statistic")

```

From both of these boxplots we see that most samples are generally well covered,
with the average and median coverages of the data at about 100x. Futhermore,
about the median of samples have 
`r as.numeric(quantile(dp_df$'%_bases_above_10', c(0.5)))`\% of their bases covered at
10x. Again we see that there are a few problematic samples that are poorly 
covered did not align well to the 3D7 reference.

We also make boxplots of coverage at known resistance loci for both.

```{r interval-summary}
interval_pattern <- sub("sample_summary", "sample_interval_summary", dp_pattern)
interval_summary <- list.files(qc_path, pattern = interval_pattern,
                              full.names = TRUE)

targets <- read_delim("data/annotations/drug_resistance_genes.bed", 
                      delim = " ",
                    col_names = c("chromosome", "start", "end", 
                                  "gene.id", "score", "strand")) %>% 
    mutate(id = paste0(chromosome, ":", start + 1, "-", end + 1))
read_interval <- function(interval_file) {
    x <- read_tsv(interval_file)
    x1 <- x %>% select(Target, ends_with("cvg"), contains("%")) 
    x2 <- x1 %>% gather(sample_statistic, value, -Target)
    if (all(grepl("^PNG", x2$sample_statistic))) {
        x2 %>% 
            mutate(sample_statistic = sub("_", "-", sample_statistic)) %>% 
            separate(sample_statistic, c("sample", "statistic"), "_", extra = "merge") %>% 
            mutate(sample = sub("-", "_", sample))
            
    } else {
        x2 %>% separate(sample_statistic, 
                        c("sample", "statistic"), "_", extra = "merge")
    }
}

interval_df <- lapply(interval_summary, read_interval) %>% bind_rows()

interval_df <- left_join(interval_df, targets, by = c("Target" = "id"))

ggplot(interval_df %>% filter(statistic %in% c("mean_cvg")), 
       aes(x = factor(statistic), y = value)) +
    geom_boxplot() + facet_grid(. ~ gene.id ) +
    theme(axis.text.x = element_text(angle = 90),
          strip.text = element_text(size = 6))

ggplot(interval_df %>% filter(grepl("%", statistic)), 
                              aes(x = factor(statistic), y = value)) +
    geom_boxplot() + facet_grid(. ~ gene.id ) +
    theme(axis.text.x = element_text(angle = 90),
          strip.text = element_text(size = 6))
```

In general we are pretty well covered accross most resistance genes.


## FastQC
We ran FastQC to check the base quality score distributions and
GC content post alignment. 

The summary results are located in data/qc/ and are available as zip files.
Aside from the probelmatic samples identified above - generally the quality
of the sequencing data was reasonble.

We provide links to the html files generated by FastQC for all samples here:
```{r fastqc-results, results='asis'}

fastqc_reports <- list.files(qc_path, 
                             pattern = "*bqsrApply_fastqc.html", 
                             full.names = TRUE)
sample_id <-  sub("(.*\\/)", "\\2", fastqc_reports)
sample_id <- sub("\\..*", "\\2", sample_id)
cat(paste0("[", sample_id, "](", fastqc_reports, ")\n"))
```


## Variant and sample filtering
```{r open-gds}
variants <- seqOpen(final_vcf)
# summary
variant_id <- seqGetData(variants, "variant.id") 
sample_id <- seqGetData(variants, "sample.id")

```
After running the sequencing data through the updated variant calling pipeline,
we initially filtered variants on the following characteristics

- remove indels
- keep only biallelic SNVs
- remove variants not on core chromosomal regions
- remove variants with VQSR LOD score less than or equal to 0.
- remove variants if there are three or more SNVs within a 30 base pair window

This left us with `r length(variant_id)` biallelic SNVs. To begin filtering
we remove the problematic samples identified above according to the following criteria:

* remove a sample if less than 90% of their bases are not covered to at
    least 5 reads

This filter ensures that samples that consist of mostly human or Pvivax reads will be
removed from downstream analysis, it also ensures that a sample should be genotyped with
reasonable confidence. 

```{r sample-filtering1}
sample_filter1 <- (left_join(align_df_clean %>% 
                                select(sample_id, percent_high_qual_aligned, percent_adapter),
                            dp_df %>% 
                                select(sample_id, x5 = `%_bases_above_5`) %>% 
                                mutate(sample_id = sub("-", "_", sample_id))) %>% 
    filter(x5 >= 90))$sample_id

samples_kept <- ifelse(grepl("^PNG", sample_filter1),
                       sample_filter1, 
                       sub("_", "-", sample_filter1))

seqSetFilter(variants, sample.id  = samples_kept)
```

After applying this filter, we are left with `r length(sample_filter1)` samples. Next we look at the
quality annotations provided by the GATK Haplotype Caller output. 

```{r qual-output}
gatk_df <- data.frame(variant.id = seqGetData(variants, "variant.id"),
                      chr = seqGetData(variants, "chromosome"),
                      mq =  seqGetData(variants, "annotation/info/MQ"),
                      mqrank = seqGetData(variants, "annotation/info/MQRankSum"),
                      qd = seqGetData(variants, "annotation/info/QD"),
                      sor = seqGetData(variants, "annotation/info/SOR"))


print(ggplot(gatk_df, aes(x = mq)) + stat_ecdf())
print(ggplot(gatk_df, aes(x = mqrank)) + stat_ecdf())
print(ggplot(gatk_df, aes(x = qd)) + stat_ecdf())
print(ggplot(gatk_df, aes(x =  sor)) + stat_ecdf())

filter_reads <-  function(x) {
    x[x<5] <- NA 
    sum(x, na.rm = TRUE)
}

gatk_df$dp <- seqApply(variants, "annotation/format/AD",
              filter_reads, margin = "by.variant", as.is = "double")
print(ggplot(gatk_df, aes(x =  dp)) + stat_ecdf())

dp_quantiles <- quantile(gatk_df$dp, c(0.15, 0.85))
# filter based on field samples
# filter based on qd > 15, sor < 1, mqrank > -2 , MQ > 50

v_ids <- (gatk_df %>% filter(chr != "Pf3D7_API_v3", 
                             qd > 15, 
                             mq > 50, 
                             sor < 1,
                             dp > dp_quantiles[1],
                             dp < dp_quantiles[2],
                             mqrank > -2 | is.na(mqrank)))$variant.id
```


We see that all variants are supported by high residual mean square mapping
qualities over all samples. The distribution of MQRankSum scores (which is only
computed at heterozygous sites) is centred at 0 with a fat right tail. For this
tag only negative scores are useful since that indicates that the mapping quality
for the alternate allele is low compared to the reference allele. The QD distribution
is relatively symmetric and centred at around 25, most variants have relatively
good ratios of  average quality to average depth. The SOR tag is an odds
ratio score to detect strand bias from a 2 x 2 contingency table using the strands
and alt/ref allele counts as the rows and columns respectively. In order to remove variants
with high-evidence for strand-biasedness we select varaints with SOR < 1.

We apply some hard filters to all samples:

* QD score > 15
* SOR < 1
* MQRankSum > -2 (allowed to be missing for sites with heterozygous calls)
* MQ > 50
* DP between `r paste(dp_quantiles, collapse = " and ")`, these are the 15th and
85th percentiles of the coverage distribution, resepcitvely. 
This should prevent PCR amplification artefacts.

Next we look at the minor-allele frequency distribution estimated directly from the
read-count data, we also look at the empirical coverage within samples distributions estimated at 5x, 10x, and 20x over all SNPs.

```{r maf}
seqSetFilter(variants, variant.id = v_ids)
maf_pass1 <- getMAF(variants)

hist(maf_pass1, breaks = 100)

sample_5x <- perSiteCoverageBySNP(variants, 5L)
sample_10x <- perSiteCoverageBySNP(variants, 10L)
sample_20x <- perSiteCoverageBySNP(variants, 20L)
plot(ecdf(sample_5x),
     xlab = "Proportion of samples",
     ylab = "Cumulative proportion of SNPs",
     main= paste("ECDF coverage at various thresholds."))
lines(ecdf(sample_10x), col = "darkblue")
lines(ecdf(sample_20x), col = "magenta")
legend('left', 
       c('5x', '10x', '20x'), 
       fill=c("black", "darkblue", "magenta") ,
       border=NA)

v_ids_maf <- v_ids[maf_pass1 > 0.01]
```

The MAF distribution looks similar to those found in other regions, where
we find that many SNVs are rare in the populations of interest. We also find
that the selected samples are fairly well covered accross all SNVs in the included
set - meaning we can be relatively confident in their genotype calls.

# Estimating MOI with $F_{ws}$

First, we plot the B-allele frequency distrubitions for the remaining SNVs and
samples. There are few samples with a strong signal indicating that there
are multiple infections. 
```{r baf-plots, include=FALSE}
bf <- bafMatrix(variants)

for (sample in sort(samples_kept)) {
    plot(bf, sample)
}

```

Next we estimate the $F_{ws}$ metric and plot the results.

```{r fws}
fws_sample <- getFws(variants)

ggplot(data = data.frame(fws = as.numeric(fws_sample)), 
       aes(x = factor(0), y= fws)) + geom_boxplot()
moi <- ifelse(fws_sample < 0.95, 2L, 1L)
```

Using an $F_{ws}$ cut-off of 0.95, we obtain `r sum(moi == 2)` multiclonal
isoaltes, which aligns with previous estimates found in our old pipeline and
using `moimix`.

# Extracting data for IBD analysis

Next we extract data for IBD analysis using the MOI estimates obtained above.
We also apply a MAF filter by selecting SNPs that are above 1\% frequency.
This reduces our callset to `r length(v_ids_maf)` SNPs.

```{r ibd-data}

seqSetFilter(variants, variant.id = v_ids_maf)

annotations <- read_tsv("cache/final_annotations.txt",
                        col_names = c("chr", "pos",
                                      "ref_allele", "alt_allele", "annotated_allele",
                                      "barcode", "dp", "gene_id", "gene_biotype",
                                      "snp_effect", "snp_aa_change", "annotation_errors"
                                      ),
                        skip = 1) %>% 
    select(chr, pos, ref_allele, alt_allele,
           gene_id, gene_biotype, snp_effect, snp_aa_change) %>% distinct()

coords_final <- getCoordinates(variants) %>% 
    select(chr = chromosome, pos = position)

annotations_final <- left_join(coords_final, annotations)

# region summary
region_summary <- list(maf = maf_pass1, 
                       annotations = annotations_final, 
                       fws = fws_sample)

write_rds(region_summary, "cache/png_summary.rds")

# extract PED
region_plink <- extractPED(variants, moi.estimates = moi)
write_rds(region_plink, "cache/png_ped.rds")

# extract genotypes / allele counts
region_genotypes <- alleleCounts(variants)
write_rds(region_genotypes, "cache/png_acounts.rds")

seqSetFilter(variants, variant.id = v_ids)

coords <- getCoordinates(variants)
snp_out <- "cache/png_summary_positions.txt"
sample_out <- "cache/png_summary_samples.txt"

write_tsv(coords, snp_out, col_names = FALSE)

moi1 <- data.frame(sample_id = names(moi), moi = moi) %>% 
    filter(moi == 1)

write_tsv(moi1 %>% select(sample_id), 
          sample_out, 
          col_names = FALSE)

```

# Extracting data for selection analysis

Finally, we output data for use in our selection piepline using the python
package `scikit-allel`. We extract samples that have MOI = 1 and use the variant
list we obtained before. 

```{r hdf5-pipeline}
print("Now creating HDF5 file for PNG")

system("source activate py27")

raw_vcf <- "cache/final_snps.vcf.gz"

vcf_out <- "cache/png_maf_moi1_filtered.vcf.gz"

vcf_filter <- paste(vcftools_bin, "--gzvcf", raw_vcf,
                    "--keep", sample_out,
                    "--positions", snp_out,
                    "--recode --recode-INFO-all --stdout |",
                    bgzip, "-c >",  vcf_out, ";", 
                    tabix, vcf_out ) 

system(vcf_filter)

# create npy arrays
cache_dir <- paste0("cache/png_vcf2npy_cache")
chrom <- unique(coords$chromosome)

# create h5 file, grouping by chromsome name
# h5 file
hdf5_region <- "cache/png_final.h5"

for(chr in chrom) {
    npy_cmd1 <- paste(vcf2npy_bin, "--vcf",
                      vcf_out,
                      "--output-dir", cache_dir,
                      "--chromosome", chr,
                      "--ploidy 2 --array-type calldata_2d")
    system(npy_cmd1)
    
    npy_cmd2 <- sub("calldata_2d", "variants", npy_cmd1)
    system(npy_cmd2)
    
    hdf5_cmd <- paste(vcfnpy2hdf5_bin, "--vcf", vcf_out,
                      "--input-dir", cache_dir,
                      "--input-filename-template",
                      paste0("{array_type}.", chr, ".npy"),
                      "--output", hdf5_region,
                      "--group", chr)
    system(hdf5_cmd)
}
system("source deactivate")
```

# Appendix
```{r sessionInfo}
sessionInfo()
```
